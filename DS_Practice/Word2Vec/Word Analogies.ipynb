{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Word Analogies Task </b>\n",
    "\n",
    "- In the word analogy task, we complete the sentence \"a is to b as c is to ___\". An example is 'man is to woman as king is to queen'.In detail, we are trying to find\n",
    "a word d,such that the associated word vectors ea,eb,ec,ed are related in the following manner: eb-ea=ed-ec. We will measure\n",
    "    the similarity between eb-ea and ed-ec using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(a,b,c,word_vectors):\n",
    "    \n",
    "    a,b,c=a.lower(),b.lower(),c.lower()\n",
    "    \n",
    "    #similarity between |b-a| =|d-c| should  be max\n",
    "    max_similarity = -100\n",
    "    \n",
    "    d = None\n",
    "    \n",
    "    words = word_vectors.vocab.keys() \n",
    "    \n",
    "    wa,wb,wc= word_vectors[a],word_vectors[b],word_vectors[c]\n",
    "    \n",
    "    #to find d s.t similiarity (|b-a|,|d-c|) should be max\n",
    "    \n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        \n",
    "        wv=word_vectors[w]\n",
    "        sim= cosine_similarity([wb-wa],[wv-wc])\n",
    "        \n",
    "        if sim> max_similarity:\n",
    "            max_similarity= sim\n",
    "             d = w\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'princess'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad_2=(\"man\",\"woman\",\"prince\")\n",
    "predict_word(*triad_2,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using the most similar method</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['woman','king'], negative=['man'],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
